{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f675746e-6c69-40dc-a220-337a0f9dcb4d",
   "metadata": {},
   "source": [
    "## BankCustomerChurn Module that contain the ML model selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b2e9372-d7c5-4397-a0cd-3641573524aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class CustomScaler(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,columns,copy=True,with_mean=True,with_std=True):\n",
    "        self.scaler = StandardScaler(copy=copy,with_mean=with_mean,with_std=with_std)\n",
    "        self.columns = columns\n",
    "        self.with_mean = with_mean\n",
    "        self.with_std = with_std\n",
    "        self.copy = copy\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[self.columns],y)\n",
    "        self.mean_ = np.mean(X[self.columns])\n",
    "        self.std_ = np.std(X[self.columns])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        init_col_order = X.columns\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns= self.columns)\n",
    "        X_notscaled = X.loc[:,~X.columns.isin(self.columns)]\n",
    "        return pd.concat([X_notscaled,X_scaled], axis = 1)[init_col_order]\n",
    "\n",
    "\n",
    "# CustomerChurn class for managing training, prediction, and preprocessing\n",
    "class CustomerChurn:\n",
    "\n",
    "    def __init__(self, model_file, scaler_file):\n",
    "        # Load the trained model and scaler\n",
    "        with open(model_file, 'rb') as model_file_obj:\n",
    "            self.model_selected = pickle.load(model_file_obj)\n",
    "        with open(scaler_file, 'rb') as scaler_file_obj:\n",
    "            self.scaler_selected = pickle.load(scaler_file_obj)\n",
    "        self.data = None\n",
    "\n",
    "    def load_and_clean_data(self, data_file):\n",
    "        # Import the new data ** (which does not contain the target column)\n",
    "        df = pd.read_csv(data_file, delimiter=',')\n",
    "\n",
    "        # Store data in a new instance variable (to keep original data intact)\n",
    "        # self.df_with_predictions = df.copy()\n",
    "\n",
    "        # Remove columns not necessary for the model (similar to training preprocessing)\n",
    "        df = df.drop(['RowNumber', 'CustomerId', 'Surname', 'Complain'], axis=1)\n",
    "        \n",
    "        # Identify numerical columns to scale ( same selection as the data cleaning stage)\n",
    "        numerical_cols = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', \n",
    "                          'EstimatedSalary', 'Satisfaction Score', 'Point Earned']\n",
    "\n",
    "        # Apply the saved scaler to standardize the numerical columns using the pre-trained scaler\n",
    "        df[numerical_cols] = self.scaler_selected.transform(df[numerical_cols])\n",
    "\n",
    "        # Create dummy variables for categorical columns / notice that here we code that the variable type 'objects' will be selected\n",
    "        categorical_cols = ['Geography', 'Gender', 'Card Type']\n",
    "        df = pd.get_dummies(df, columns=categorical_cols, drop_first=True, dtype='int')\n",
    "        df = df['HasCrCard', 'IsActiveMember', 'CreditScore', 'Age', 'Tenure',\n",
    "       'Balance', 'NumOfProducts', 'EstimatedSalary', 'Satisfaction Score',\n",
    "       'Point Earned', 'Geography_Germany', 'Geography_Spain', 'Gender_Male',\n",
    "       'Card Type_GOLD', 'Card Type_PLATINUM', 'Card Type_SILVER']\n",
    "        \n",
    "        # Store the preprocessed data for later use\n",
    "        self.data = df.copy()\n",
    "        return self.data\n",
    "\n",
    "    def predict_churn(self):\n",
    "        # Make predictions using the trained model\n",
    "        predictions = self.model_selected.predict(self.data)\n",
    "\n",
    "        # Add the predictions to the original data (for easy comparison)\n",
    "        self.data['Predicted_Exited'] = predictions\n",
    "        \n",
    "        return self.data # Return both  self.data that now contain a new column 'Predicted_Exited\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc75c1e0-a0f0-40d9-b1fc-7ee498d9e0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1effb8da-14d9-4741-80ca-1e36d6de4543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
